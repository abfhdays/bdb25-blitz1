{"cells":[{"cell_type":"code","source":["def process_week_data(\n","    week_number: int,\n","    plays: pd.DataFrame,\n","    players: pd.DataFrame | None = None,\n","    data_root: str = \"/content/drive/MyDrive/bdb25-blitz/data/raw\",\n","    out_dir: str  = \"/content/drive/MyDrive/bdb25-blitz/artifacts\",\n","    even_frames_only: bool = True,\n","    label_blitz: bool = True,\n","    add_disguise: bool = True,\n","    return_df: bool = False,\n","):\n","    \"\"\"\n","    Streams week CSV in chunks, keeps all cols, applies cleaning,\n","    adds LOS/depth/angles, (optional) disguise features, (optional) blitz labels,\n","    windows to [-0.8s, +0.5s] around snap, writes single Parquet.\n","    \"\"\"\n","    os.makedirs(out_dir, exist_ok=True)\n","    file_path = os.path.join(data_root, f\"tracking_week_{week_number}.csv\")\n","    out_path  = os.path.join(out_dir,   f\"week_{week_number:02d}_clean_blitz.parquet\")\n","\n","    # restrict to dropbacks early\n","    dropbacks = plays.loc[plays[\"isDropback\"] == True, [\"gameId\",\"playId\",\"defensiveTeam\",\"possessionTeam\"]].drop_duplicates()\n","    key_set = set(map(tuple, dropbacks[[\"gameId\",\"playId\"]].to_numpy()))\n","    print(f\"[Week {week_number}] scanning for snap frames…\")\n","\n","    # PASS A — collect snap frames\n","    snap_map = {}\n","    for chunk in pd.read_csv(file_path, chunksize=1_000_000):\n","        mask = [tuple(x) in key_set for x in chunk[[\"gameId\",\"playId\"]].to_numpy()]\n","        if not any(mask): continue\n","        small = chunk.loc[mask, [\"gameId\",\"playId\",\"frameId\",\"event\"]]\n","        snaps = small.loc[small[\"event\"].isin([\"ball_snap\",\"ball_snap_penalty\"])]\n","        if not snaps.empty:\n","            grp = snaps.groupby([\"gameId\",\"playId\"])[\"frameId\"].min()\n","            for (g,p), f in grp.items():\n","                k = (int(g), int(p))\n","                snap_map[k] = min(f, snap_map.get(k, f))\n","        del chunk, small, snaps; gc.collect()\n","\n","    if not snap_map:\n","        print(f\"[Week {week_number}] no dropback snaps found; skipping.\")\n","        return {\"week\": week_number, \"saved\": False, \"path\": None}\n","\n","    print(f\"[Week {week_number}] found {len(snap_map)} snaps. Building cleaned window…\")\n","\n","    # (optional) merge positions for later sim/creeper detection\n","    players_small = None\n","    if players is not None and {'nflId','position'}.issubset(players.columns):\n","        players_small = players[['nflId','position']].drop_duplicates()\n","\n","    first_write, part_files = True, []\n","\n","    # PASS B — stream, clean, window, enrich, write\n","    for chunk in pd.read_csv(file_path, chunksize=600_000):\n","        mask = [tuple(x) in snap_map for x in chunk[[\"gameId\",\"playId\"]].to_numpy()]\n","        if not any(mask): continue\n","        chunk = chunk.loc[mask].copy()\n","\n","        # ensure dis\n","        if \"x\" in chunk.columns and \"y\" in chunk.columns:\n","            _ensure_distance_column_inplace(chunk)\n","\n","        # cleaning\n","        chunk = rotate_direction_and_orientation(chunk)\n","        chunk = make_plays_left_to_right(chunk)\n","        chunk = calculate_velocity_components(chunk)\n","        chunk = pass_attempt_merging(chunk, plays)\n","\n","        # add defense flag (like your labelers do)\n","        chunk = chunk.merge(dropbacks, on=['gameId','playId'], how='left')\n","        chunk['defense'] = ((chunk['club'] == chunk['defensiveTeam']) & (chunk['club'] != 'football')).astype(int)\n","\n","        # IDs\n","        chunk[\"week\"] = week_number\n","        chunk[\"uniqueId\"] = chunk[\"gameId\"].astype(\"string\") + \"_\" + chunk[\"playId\"].astype(\"string\")\n","        chunk[\"frameUniqueId\"] = chunk[\"uniqueId\"] + \"_\" + chunk[\"frameId\"].astype(\"string\")\n","\n","        # snap/window\n","        sf = np.array([snap_map[(g,p)] for g,p in chunk[[\"gameId\",\"playId\"]].to_numpy()], dtype=np.int32)\n","        chunk[\"snap_frame\"] = sf\n","        chunk[\"frames_from_snap\"] = chunk[\"frameId\"].astype(\"int32\") - chunk[\"snap_frame\"]\n","        if even_frames_only:\n","            chunk = chunk[(chunk[\"frameId\"] % 2) == 0]\n","        chunk = chunk[(chunk[\"frames_from_snap\"] >= -T_PRE_FRAMES) & (chunk[\"frames_from_snap\"] <= T_POST_FRAMES)]\n","        if chunk.empty:\n","            del chunk; gc.collect(); continue\n","\n","        # LOS/depth/angles\n","        chunk = add_los_depth_and_angles(chunk)\n","\n","        # disguise features (pre-snap creep deltas), optional\n","        if add_disguise:\n","            chunk = add_disguise_features(chunk, pre_window=(-8, 0))\n","\n","        # players positions (for sim/creeper). Join once per chunk if provided.\n","        if players_small is not None and 'position' not in chunk.columns:\n","            chunk = chunk.merge(players_small, on='nflId', how='left')\n","\n","        # blitz labels (play-level), optional\n","        if label_blitz:\n","            # Make sure we only compute on plays present in this chunk (faster)\n","            chunk = make_blitz_labels(chunk, players_small)\n","\n","        # write\n","        if first_write:\n","            chunk.to_parquet(out_path, index=False)\n","            first_write = False\n","        else:\n","            tmp = out_path.replace(\".parquet\", f\".part_{np.random.randint(1e9)}.parquet\")\n","            chunk.to_parquet(tmp, index=False)\n","            part_files.append(tmp)\n","\n","        del chunk; gc.collect()\n","\n","    # consolidate parts\n","    if part_files:\n","        base = pd.read_parquet(out_path) if os.path.exists(out_path) else None\n","        dfs = ([base] if base is not None else []) + [pd.read_parquet(p) for p in part_files]\n","        pd.concat(dfs, ignore_index=True).to_parquet(out_path, index=False)\n","        for p in part_files:\n","            try: os.remove(p)\n","            except: pass\n","\n","    print(f\"[Week {week_number}] saved → {out_path}\")\n","    if return_df:\n","        return pd.read_parquet(out_path)\n","    return {\"week\": week_number, \"saved\": True, \"path\": out_path}"],"metadata":{"id":"WiVogLNN_qON"},"execution_count":null,"outputs":[],"id":"WiVogLNN_qON"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from google.colab import drive\n","import torch\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","drive.mount('/content/drive')\n","\n","# reading static CSV files (currently in GDrive)\n","games = pd.read_csv(\"/content/drive/MyDrive/bdb25-blitz/data/raw/games.csv\")\n","player_play = pd.read_csv(\"/content/drive/MyDrive/bdb25-blitz/data/raw/player_play.csv\")\n","players = pd.read_csv(\"/content/drive/MyDrive/bdb25-blitz/data/raw/players.csv\")\n","plays = pd.read_csv(\"/content/drive/MyDrive/bdb25-blitz/data/raw/plays.csv\")\n","\n","all_weeks = []\n","for week_number in range(1, 10):\n","    week_df = process_week_data(\n","        week_number,\n","        plays,\n","        return_df=True,          # <- make it return a DataFrame\n","        even_frames_only=True\n","    )\n","    if isinstance(week_df, dict):  # in case a week was skipped\n","        continue\n","    all_weeks.append(week_df)\n","\n","all_tracking = pd.concat(all_weeks, ignore_index=True)\n","# your filters\n","all_tracking = all_tracking[\n","    (all_tracking['club'] != 'football') & (all_tracking['passAttempt'] == 1)\n","]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNHUnowdAFhr","outputId":"158e6d40-b617-4db1-d340-147488537c2f","executionInfo":{"status":"ok","timestamp":1757865213791,"user_tz":240,"elapsed":976356,"user":{"displayName":"Aarush Ghosh","userId":"07665484170756829341"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[Week 1] scanning for snap frames…\n","[Week 1] found 1218 snaps. Building cleaned window…\n","[Week 1] saved → /content/drive/MyDrive/bdb25-blitz/artifacts/week_01_clean_blitz.parquet\n","[Week 2] scanning for snap frames…\n","[Week 2] found 1111 snaps. Building cleaned window…\n","[Week 2] saved → /content/drive/MyDrive/bdb25-blitz/artifacts/week_02_clean_blitz.parquet\n","[Week 3] scanning for snap frames…\n","[Week 3] found 1223 snaps. Building cleaned window…\n","[Week 3] saved → /content/drive/MyDrive/bdb25-blitz/artifacts/week_03_clean_blitz.parquet\n","[Week 4] scanning for snap frames…\n","[Week 4] found 1051 snaps. Building cleaned window…\n","[Week 4] saved → /content/drive/MyDrive/bdb25-blitz/artifacts/week_04_clean_blitz.parquet\n","[Week 5] scanning for snap frames…\n","[Week 5] found 1142 snaps. Building cleaned window…\n","[Week 5] saved → /content/drive/MyDrive/bdb25-blitz/artifacts/week_05_clean_blitz.parquet\n","[Week 6] scanning for snap frames…\n","[Week 6] found 1032 snaps. Building cleaned window…\n","[Week 6] saved → /content/drive/MyDrive/bdb25-blitz/artifacts/week_06_clean_blitz.parquet\n","[Week 7] scanning for snap frames…\n","[Week 7] found 990 snaps. Building cleaned window…\n","[Week 7] saved → /content/drive/MyDrive/bdb25-blitz/artifacts/week_07_clean_blitz.parquet\n","[Week 8] scanning for snap frames…\n","[Week 8] found 1047 snaps. Building cleaned window…\n","[Week 8] saved → /content/drive/MyDrive/bdb25-blitz/artifacts/week_08_clean_blitz.parquet\n","[Week 9] scanning for snap frames…\n","[Week 9] found 913 snaps. Building cleaned window…\n","[Week 9] saved → /content/drive/MyDrive/bdb25-blitz/artifacts/week_09_clean_blitz.parquet\n"]}],"id":"oNHUnowdAFhr"},{"cell_type":"code","source":["# --- takes ~10mins to run\n","\n","features = [\n","    \"x_clean\",\"y_clean\",\"v_x\",\"v_y\",\n","    \"depth_to_los\",\"o_to_los_cos\",\n","    \"creep_depth_mean\",\"creep_lat_mean\",\"pre_speed_mean\"\n","]\n","target_column = \"blitz\"\n","\n","cols_common = [\n","    \"frameUniqueId\",\"displayName\",\"frameId\",\"frameType\",\n","    \"club\",\"defensiveTeam\",\"defense\", target_column,\n","    # helpers some packers may touch\n","    \"s_clean\",\"s\",\"dir_clean\",\"o_clean\",\"frames_from_snap\"\n","] + features\n","\n","def _ensure_basics(df: pd.DataFrame) -> pd.DataFrame:\n","    df = df.copy()\n","\n","    # create 'defense' if absent (defense team & not ball)\n","    if \"defense\" not in df.columns:\n","        if \"club\" in df.columns and \"defensiveTeam\" in df.columns:\n","            df[\"defense\"] = ((df[\"club\"] == df[\"defensiveTeam\"]) & (df[\"club\"] != \"football\")).astype(int)\n","        else:\n","            df[\"defense\"] = 0  # fallback\n","\n","    # make sure s_clean exists (some helpers use it for speed-derived stats)\n","    if \"s_clean\" not in df.columns:\n","        if \"s\" in df.columns:\n","            df[\"s_clean\"] = df[\"s\"]\n","        else:\n","            df[\"s_clean\"] = 0.0\n","\n","    # ensure orientation/dir cleaned if packer glances at them\n","    if \"dir_clean\" not in df.columns and \"dir\" in df.columns:\n","        df[\"dir_clean\"] = (-(df[\"dir\"] - 90)) % 360\n","    if \"o_clean\" not in df.columns and \"o\" in df.columns:\n","        df[\"o_clean\"] = (-(df[\"o\"] - 90)) % 360\n","\n","    # ensure all requested features exist (fill with 0 if missing)\n","    for c in features:\n","        if c not in df.columns:\n","            df[c] = 0.0\n","\n","    # some packers expect this id\n","    if \"frameUniqueId\" not in df.columns:\n","        df[\"frameUniqueId\"] = (\n","            df[\"gameId\"].astype(str) + \"_\" + df[\"playId\"].astype(str) + \"_\" + df[\"frameId\"].astype(str)\n","        )\n","\n","    # keep just what we need (ignore missing safely)\n","    keep = [c for c in cols_common if c in df.columns]\n","    return df[keep]\n","\n","for week_eval in range(1, 10):\n","    train_df = all_tracking[all_tracking[\"week\"] != week_eval]\n","    val_df   = all_tracking[all_tracking[\"week\"] == week_eval]\n","\n","    train_df = _ensure_basics(train_df)\n","    val_df   = _ensure_basics(val_df)\n","\n","    # pack tensors (KxF per frame) + targets\n","    train_features, train_targets = prepare_frame_data_blitz(train_df, features, target_column)\n","    val_features,   val_targets   = prepare_frame_data_blitz(val_df,   features, target_column)\n","\n","    if train_features is None or val_features is None:\n","        raise RuntimeError(\n","            \"prepare_frame_data_blitz returned None (likely inconsistent per-frame shapes). \"\n","            \"Ensure the function pads/truncates to a fixed K defenders per frame.\"\n","        )\n","\n","    print(f\"Week {week_eval} Tensor: {train_features.shape}\")\n","    print(f\"Week {week_eval} Indiv Check: {train_features[63][0]}\")\n","\n","    torch.save(train_features, f\"/content/drive/MyDrive/bdb25-blitz/artifacts/features_training_week{week_eval}preds.pt\")\n","    torch.save(train_targets,  f\"/content/drive/MyDrive/bdb25-blitz/artifacts/targets_training_week{week_eval}preds.pt\")\n","\n","    torch.save(val_features,   f\"/content/drive/MyDrive/bdb25-blitz/artifacts/features_val_week{week_eval}preds.pt\")\n","    torch.save(val_targets,    f\"/content/drive/MyDrive/bdb25-blitz/artifacts/targets_val_week{week_eval}preds.pt\")\n"],"metadata":{"id":"Sfdjeb4aR00q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757866934328,"user_tz":240,"elapsed":1138136,"user":{"displayName":"Aarush Ghosh","userId":"07665484170756829341"}},"outputId":"ef39d394-e1bc-4a83-c4c3-6ff99c70c305"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Week 1 Tensor: torch.Size([55738, 8, 9])\n","Week 1 Indiv Check: tensor([ 6.0450e+01,  2.9160e+01, -5.0208e-01, -3.8055e-01,  6.2000e-01,\n","        -7.9695e-01, -2.7500e-02, -2.5000e-03,  2.2000e-01])\n","Week 2 Tensor: torch.Size([56385, 8, 9])\n","Week 2 Indiv Check: tensor([ 1.0586e+02,  2.2150e+01, -7.8419e-02,  1.2787e-01,  8.0000e-01,\n","        -5.2280e-01, -7.5000e-03,  4.5000e-02,  2.7750e-01])\n","Week 3 Tensor: torch.Size([55694, 8, 9])\n","Week 3 Indiv Check: tensor([ 1.0586e+02,  2.2150e+01, -7.8419e-02,  1.2787e-01,  8.0000e-01,\n","        -5.2280e-01, -7.5000e-03,  4.5000e-02,  2.7750e-01])\n","Week 4 Tensor: torch.Size([56775, 8, 9])\n","Week 4 Indiv Check: tensor([ 1.0586e+02,  2.2150e+01, -7.8419e-02,  1.2787e-01,  8.0000e-01,\n","        -5.2280e-01, -7.5000e-03,  4.5000e-02,  2.7750e-01])\n","Week 5 Tensor: torch.Size([56197, 8, 9])\n","Week 5 Indiv Check: tensor([ 1.0586e+02,  2.2150e+01, -7.8419e-02,  1.2787e-01,  8.0000e-01,\n","        -5.2280e-01, -7.5000e-03,  4.5000e-02,  2.7750e-01])\n","Week 6 Tensor: torch.Size([57013, 8, 9])\n","Week 6 Indiv Check: tensor([ 1.0586e+02,  2.2150e+01, -7.8419e-02,  1.2787e-01,  8.0000e-01,\n","        -5.2280e-01, -7.5000e-03,  4.5000e-02,  2.7750e-01])\n","Week 7 Tensor: torch.Size([57158, 8, 9])\n","Week 7 Indiv Check: tensor([ 1.0586e+02,  2.2150e+01, -7.8419e-02,  1.2787e-01,  8.0000e-01,\n","        -5.2280e-01, -7.5000e-03,  4.5000e-02,  2.7750e-01])\n","Week 8 Tensor: torch.Size([56929, 8, 9])\n","Week 8 Indiv Check: tensor([ 1.0586e+02,  2.2150e+01, -7.8419e-02,  1.2787e-01,  8.0000e-01,\n","        -5.2280e-01, -7.5000e-03,  4.5000e-02,  2.7750e-01])\n","Week 9 Tensor: torch.Size([57735, 8, 9])\n","Week 9 Indiv Check: tensor([ 1.0586e+02,  2.2150e+01, -7.8419e-02,  1.2787e-01,  8.0000e-01,\n","        -5.2280e-01, -7.5000e-03,  4.5000e-02,  2.7750e-01])\n"]}],"id":"Sfdjeb4aR00q"}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}