{"cells":[{"cell_type":"code","source":["import os, random, pandas as pd, torch\n","from torch.utils.data import TensorDataset\n","\n","# ---- config ----\n","PROJ = \"/content/drive/MyDrive/bdb25-blitz\"\n","ART  = f\"{PROJ}/artifacts\"   # where week_XX_clean_blitz.parquet lives\n","os.makedirs(ART, exist_ok=True)\n","\n","# your new feature set + target\n","features = [\"x_clean\",\"y_clean\",\"v_x\",\"v_y\",\"depth_to_los\",\"o_to_los_cos\",\n","            \"creep_depth_mean\",\"creep_lat_mean\",\"pre_speed_mean\"]\n","target_column = \"blitz\"\n","\n","# K defenders kept per frame inside prepare_frame_data_blitz (must match your helper default)\n","K_DEF = 8\n","\n","# minimal columns we’ll require from parquet (don’t drop anything else while writing parquet)\n","NEEDED = [\"frameUniqueId\",\"frameId\",\"frameType\",\"defensiveTeam\",\"defense\", target_column] + features\n","\n","def load_week_df(week: int) -> pd.DataFrame:\n","    path = f\"{ART}/week_{week:02d}_clean_blitz.parquet\"\n","    df = pd.read_parquet(path)\n","    missing = [c for c in NEEDED if c not in df.columns]\n","    if missing:\n","        raise KeyError(f\"Week {week:02d} missing columns: {missing}. \"\n","                       \"Ensure process_week_data added LOS/disguise/labels first.\")\n","    # keep only rows that have a target (some plays might not have labels if filtered)\n","    df = df.dropna(subset=[target_column]).copy()\n","    return df\n","\n","# NOTE: this calls the new defense-only packer you wrote earlier\n","# def prepare_frame_data_blitz(df, features, target_column, K=8) -> (torch.Tensor[N,K,F], torch.Tensor[N])\n","\n","for week_eval in range(1, 10):\n","    print(f\"\\n=== Eval week {week_eval:02d} ===\")\n","\n","    # ------- Validation (single week) -------\n","    val_df = load_week_df(week_eval)\n","    val_features, val_targets = prepare_frame_data_blitz(val_df, features, target_column, K=K_DEF)\n","    if val_features is None:\n","        print(f\"[val] week {week_eval:02d}: no frames after packing; skipping.\")\n","        continue\n","\n","    # quick random sample check\n","    ridx = random.randrange(len(val_features))\n","    print(f\"[val] shape={val_features.shape}  sample[{ridx}][0]={val_features[ridx][0]}\")\n","\n","    torch.save(val_features, f\"{ART}/features_val_week{week_eval:02d}.pt\")\n","    torch.save(val_targets,  f\"{ART}/targets_val_week{week_eval:02d}.pt\")\n","\n","    # ------- Training (all other weeks) saved as shards -------\n","    shard_feats, shard_tgts = [], []\n","    for wk in range(1, 10):\n","        if wk == week_eval:\n","            continue\n","        tr_df = load_week_df(wk)\n","        trX, trY = prepare_frame_data_blitz(tr_df, features, target_column, K=K_DEF)\n","        if trX is None:\n","            print(f\"[train shard] week {wk:02d}: empty after packing; skipping.\")\n","            continue\n","\n","        fpath = f\"{ART}/features_train_week{week_eval:02d}_shard_w{wk:02d}.pt\"\n","        tpath = f\"{ART}/targets_train_week{week_eval:02d}_shard_w{wk:02d}.pt\"\n","        torch.save(trX, fpath)\n","        torch.save(trY, tpath)\n","        shard_feats.append(fpath); shard_tgts.append(tpath)\n","\n","        rtr = random.randrange(len(trX))\n","        print(f\"[train shard w{wk:02d}] shape={trX.shape}  sample[{rtr}][0]={trX[rtr][0]}\")\n","\n","    print(f\"Saved {len(shard_feats)} train shards for eval week {week_eval:02d} in {ART}\")\n","\n","    # OPTIONAL: if you truly need one big train tensor (can be large), concat on-disk cautiously:\n","    # catX, catY = [], []\n","    # for f,t in zip(shard_feats, shard_tgts):\n","    #     catX.append(torch.load(f, map_location='cpu'))\n","    #     catY.append(torch.load(t, map_location='cpu'))\n","    # train_features = torch.cat(catX, dim=0)\n","    # train_targets  = torch.cat(catY, dim=0)\n","    # torch.save(train_features, f\"{ART}/features_training_week{week_eval:02d}.pt\")\n","    # torch.save(train_targets,  f\"{ART}/targets_training_week{week_eval:02d}.pt\")\n","    # print(f\"[train concat] {train_features.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSNQa4tT29tk","executionInfo":{"status":"ok","timestamp":1757868329528,"user_tz":240,"elapsed":1292264,"user":{"displayName":"Aarush Ghosh","userId":"07665484170756829341"}},"outputId":"a9f297c3-60eb-4773-9143-2e098bb2b0cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Eval week 01 ===\n","[val] shape=torch.Size([8501, 8, 9])  sample[3381][0]=tensor([ 3.6000e+01,  2.2100e+01, -1.1547e+00, -4.7876e-01,  4.2000e-01,\n","        -9.2375e-01, -2.5000e-03, -2.5000e-03,  0.0000e+00])\n","[train shard w02] shape=torch.Size([7759, 8, 9])  sample[6899][0]=tensor([107.6100,  31.8100,   1.5057,  -2.0083,   1.6500,   0.5999,   0.2375,\n","         -0.3100,   2.5275])\n","[train shard w03] shape=torch.Size([8541, 8, 9])  sample[2730][0]=tensor([ 6.0400e+01,  3.7890e+01, -1.5985e-02,  1.2020e-02,  5.4000e-01,\n","        -7.9927e-01,  0.0000e+00,  2.5000e-03,  2.5000e-02])\n","[train shard w04] shape=torch.Size([7348, 8, 9])  sample[2332][0]=tensor([ 4.4950e+01,  2.4640e+01, -1.0345e+00, -1.0690e-01,  3.1000e-01,\n","        -9.9470e-01, -1.0000e-02, -2.5000e-03,  7.2500e-02])\n","[train shard w05] shape=torch.Size([7982, 8, 9])  sample[5018][0]=tensor([ 6.9840e+01,  2.8200e+01, -5.4999e-01,  2.3998e-03,  8.8000e-01,\n","        -9.9999e-01, -2.0000e-03,  0.0000e+00,  1.2000e-02])\n","[train shard w06] shape=torch.Size([7201, 8, 9])  sample[4910][0]=tensor([ 3.6430e+01,  2.7310e+01, -1.5577e+00, -8.5179e-02,  3.9000e-01,\n","        -9.9851e-01, -6.0000e-03,  8.0000e-03,  1.1800e-01])\n","[train shard w07] shape=torch.Size([6915, 8, 9])  sample[1525][0]=tensor([ 5.4980e+01,  2.8970e+01, -0.0000e+00, -0.0000e+00,  9.6000e-01,\n","        -8.8204e-01, -1.0000e-02,  0.0000e+00,  1.2500e-02])\n","[train shard w08] shape=torch.Size([7319, 8, 9])  sample[1337][0]=tensor([ 6.0970e+01,  1.8610e+01,  0.0000e+00,  0.0000e+00,  1.7300e+00,\n","         3.4186e-01, -2.0000e-03, -2.0000e-03,  4.0000e-03])\n","[train shard w09] shape=torch.Size([6381, 8, 9])  sample[1318][0]=tensor([ 5.9600e+01,  2.6520e+01, -7.9221e-02,  7.6316e-02,  7.1000e-01,\n","        -7.2019e-01, -2.7500e-02,  7.5000e-03,  1.0500e-01])\n","Saved 8 train shards for eval week 01 in /content/drive/MyDrive/bdb25-blitz/artifacts\n","\n","=== Eval week 02 ===\n","[val] shape=torch.Size([7759, 8, 9])  sample[1965][0]=tensor([ 9.3550e+01,  2.5910e+01,  3.7099e-03, -1.9653e-02,  1.5600e+00,\n","         1.8550e-01, -4.0000e-03, -8.0000e-03,  4.0000e-02])\n","[train shard w01] shape=torch.Size([8501, 8, 9])  sample[1858][0]=tensor([ 3.0150e+01,  3.5280e+01, -0.0000e+00,  0.0000e+00,  1.2400e+00,\n","        -5.2859e-01, -1.2000e-02,  2.8000e-02,  0.0000e+00])\n","[train shard w03] shape=torch.Size([8541, 8, 9])  sample[7655][0]=tensor([ 6.1600e+01,  3.0150e+01, -0.0000e+00,  0.0000e+00, -3.0001e-02,\n","        -3.7574e-01,  2.5000e-03, -7.5000e-03,  2.0000e-02])\n","[train shard w04] shape=torch.Size([7348, 8, 9])  sample[4051][0]=tensor([ 5.5400e+01,  2.9160e+01, -9.9909e-03, -1.7326e-02,  5.5000e-01,\n","        -4.9955e-01, -2.5000e-03, -2.5000e-03,  5.0000e-03])\n","[train shard w05] shape=torch.Size([7982, 8, 9])  sample[1733][0]=tensor([ 6.3440e+01,  1.7950e+01, -2.9003e-03, -9.5702e-03,  7.5000e-01,\n","        -2.9003e-01,  2.0000e-03,  1.4000e-02,  3.2000e-02])\n","[train shard w06] shape=torch.Size([7201, 8, 9])  sample[7179][0]=tensor([ 3.3490e+01,  3.7110e+01, -2.1393e+00, -5.3405e-02,  7.2000e-01,\n","        -9.9969e-01, -3.4000e-02,  1.6000e-02,  2.9600e-01])\n","[train shard w07] shape=torch.Size([6915, 8, 9])  sample[3947][0]=tensor([ 4.5460e+01,  2.4100e+01,  5.2868e-03,  2.9530e-02,  7.8000e-01,\n","         1.7623e-01, -1.2500e-02,  1.2500e-02,  3.5000e-02])\n","[train shard w08] shape=torch.Size([7319, 8, 9])  sample[1087][0]=tensor([4.1580e+01, 3.0830e+01, 1.4103e-02, 1.4182e-02, 5.9000e-01, 7.0513e-01,\n","        1.2500e-02, 5.0000e-03, 1.7500e-02])\n","[train shard w09] shape=torch.Size([6381, 8, 9])  sample[870][0]=tensor([ 3.8750e+01,  3.4900e+01, -5.0044e-01, -9.8274e-02,  1.1400e+00,\n","        -9.8126e-01, -6.0000e-03, -2.0000e-03,  2.8000e-02])\n","Saved 8 train shards for eval week 02 in /content/drive/MyDrive/bdb25-blitz/artifacts\n","\n","=== Eval week 03 ===\n","[val] shape=torch.Size([8541, 8, 9])  sample[4120][0]=tensor([ 5.0620e+01,  3.3540e+01, -1.6677e+00, -2.9285e+00,  5.5700e+00,\n","        -4.9485e-01, -2.0000e-02, -7.2500e-02,  5.3250e-01])\n","[train shard w01] shape=torch.Size([8501, 8, 9])  sample[5602][0]=tensor([ 4.2210e+01,  3.6230e+01, -2.3887e+00, -3.1957e-01,  3.0000e-01,\n","        -9.9117e-01, -2.4000e-02, -6.0000e-03,  1.1800e-01])\n","[train shard w02] shape=torch.Size([7759, 8, 9])  sample[1305][0]=tensor([ 1.0641e+02,  1.7970e+01, -2.0962e-03,  9.7778e-03,  5.7000e-01,\n","        -2.0962e-01, -2.5000e-03, -1.0000e-02,  7.5000e-03])\n","[train shard w04] shape=torch.Size([7348, 8, 9])  sample[2557][0]=tensor([ 2.2780e+01,  3.5240e+01, -1.4278e+00, -8.4675e-01, -1.2000e-01,\n","        -8.6012e-01, -1.7500e-02, -1.0000e-02,  5.7500e-02])\n","[train shard w05] shape=torch.Size([7982, 8, 9])  sample[7687][0]=tensor([ 9.3900e+01,  3.5260e+01, -2.4681e+00,  6.4105e-01,  1.1000e-01,\n","        -9.6788e-01, -5.0000e-03,  5.0000e-03,  1.2500e-02])\n","[train shard w06] shape=torch.Size([7201, 8, 9])  sample[2765][0]=tensor([ 3.7430e+01,  2.5010e+01, -1.5971e-01,  9.5726e-03,  6.0000e-01,\n","        -9.9821e-01, -7.5000e-03,  5.0000e-03,  1.0750e-01])\n","[train shard w07] shape=torch.Size([6915, 8, 9])  sample[1961][0]=tensor([ 3.5180e+01,  2.5070e+01,  0.0000e+00,  0.0000e+00,  5.3000e-01,\n","         9.7496e-01, -8.0000e-03, -4.0000e-03,  5.2000e-02])\n","[train shard w08] shape=torch.Size([7319, 8, 9])  sample[3443][0]=tensor([ 5.9940e+01,  8.4100e+00,  4.4936e-02,  2.1926e-02,  8.7000e-01,\n","         8.9872e-01, -4.0000e-03, -2.0000e-03,  3.4000e-02])\n","[train shard w09] shape=torch.Size([6381, 8, 9])  sample[6113][0]=tensor([ 9.5100e+01,  9.7200e+00, -5.0508e-02,  2.8557e-01,  4.0000e-01,\n","        -1.7416e-01,  1.6000e-02,  1.2000e-02,  1.7400e-01])\n","Saved 8 train shards for eval week 03 in /content/drive/MyDrive/bdb25-blitz/artifacts\n","\n","=== Eval week 04 ===\n","[val] shape=torch.Size([7348, 8, 9])  sample[5864][0]=tensor([ 4.2800e+01,  2.6780e+01, -1.1093e+00,  7.1544e-01,  6.0000e-01,\n","        -8.4038e-01,  2.5000e-03,  0.0000e+00,  7.5000e-03])\n","[train shard w01] shape=torch.Size([8501, 8, 9])  sample[211][0]=tensor([85.9900, 38.3900,  0.5840, -1.7975,  1.5500,  0.3090,  0.0975, -0.2575,\n","         1.8175])\n","[train shard w02] shape=torch.Size([7759, 8, 9])  sample[5717][0]=tensor([7.8270e+01, 2.0190e+01, 6.7363e-02, 9.9308e-02, 7.2000e-01, 5.6136e-01,\n","        1.2500e-02, 2.5000e-02, 1.7500e-01])\n","[train shard w03] shape=torch.Size([8541, 8, 9])  sample[4013][0]=tensor([ 3.6460e+01,  2.6250e+01, -3.1941e+00, -6.5217e-01,  2.0001e-02,\n","        -9.7979e-01, -2.0000e-02,  2.5000e-03,  1.5250e-01])\n","[train shard w05] shape=torch.Size([7982, 8, 9])  sample[4454][0]=tensor([ 4.5310e+01,  1.8770e+01, -0.0000e+00,  0.0000e+00,  1.9500e+00,\n","        -1.0123e-01, -1.0000e-02,  1.0000e-02,  7.5000e-03])\n","[train shard w06] shape=torch.Size([7201, 8, 9])  sample[1471][0]=tensor([ 3.5410e+01,  2.3520e+01, -1.9802e-01, -2.8042e-02,  1.2500e+00,\n","        -9.9012e-01, -3.8000e-02,  1.2000e-02,  2.1600e-01])\n","[train shard w07] shape=torch.Size([6915, 8, 9])  sample[6519][0]=tensor([ 3.7000e+01,  1.7060e+01,  4.2789e-02, -2.3615e-01,  1.2100e+00,\n","         1.7829e-01,  8.0000e-03, -3.4000e-02,  2.3400e-01])\n","[train shard w08] shape=torch.Size([7319, 8, 9])  sample[5290][0]=tensor([ 9.2740e+01,  1.8070e+01, -1.5984e-01,  8.2780e-02,  3.2000e-01,\n","        -8.8798e-01, -1.0000e-02, -4.0000e-03,  8.2000e-02])\n","[train shard w09] shape=torch.Size([6381, 8, 9])  sample[1029][0]=tensor([ 3.5470e+01,  3.0920e+01,  1.6465e-02, -1.1354e-02,  7.2000e-01,\n","         8.2324e-01,  0.0000e+00,  2.5000e-03,  5.0000e-03])\n","Saved 8 train shards for eval week 04 in /content/drive/MyDrive/bdb25-blitz/artifacts\n","\n","=== Eval week 05 ===\n","[val] shape=torch.Size([7982, 8, 9])  sample[481][0]=tensor([ 1.0300e+02,  2.1640e+01, -6.7798e-01,  4.7879e-01,  1.5300e+00,\n","        -8.1684e-01, -5.0000e-02, -1.6000e-01,  1.1240e+00])\n","[train shard w01] shape=torch.Size([8501, 8, 9])  sample[5007][0]=tensor([ 6.3440e+01,  1.9180e+01,  0.0000e+00, -0.0000e+00,  5.3000e-01,\n","         9.9994e-01, -7.5000e-03, -2.5000e-03,  3.2500e-02])\n","[train shard w02] shape=torch.Size([7759, 8, 9])  sample[6616][0]=tensor([61.8100, 31.4300, -0.7281,  0.7977,  1.9500, -0.6742, -0.0967,  0.1500,\n","         1.3600])\n","[train shard w03] shape=torch.Size([8541, 8, 9])  sample[2313][0]=tensor([ 1.0857e+02,  2.8440e+01, -4.0345e-01, -2.2097e-01,  3.4000e-01,\n","        -8.7706e-01, -1.4000e-02, -1.0000e-02,  1.0400e-01])\n","[train shard w04] shape=torch.Size([7348, 8, 9])  sample[6235][0]=tensor([ 4.2890e+01,  1.7760e+01, -1.0375e-02, -1.3962e-01,  5.8000e-01,\n","        -7.4108e-02, -3.0000e-02, -1.2500e-01,  4.8750e-01])\n","[train shard w06] shape=torch.Size([7201, 8, 9])  sample[5870][0]=tensor([ 5.8540e+01,  2.9010e+01, -0.0000e+00, -0.0000e+00,  8.2000e-01,\n","        -6.5948e-01, -2.0000e-03,  2.0000e-03,  1.4000e-02])\n","[train shard w07] shape=torch.Size([6915, 8, 9])  sample[3166][0]=tensor([ 3.9870e+01,  3.0570e+01, -1.1965e-01, -9.0460e-02,  5.0000e-01,\n","        -7.9769e-01, -1.5000e-02, -1.5000e-02,  1.9750e-01])\n","[train shard w08] shape=torch.Size([7319, 8, 9])  sample[214][0]=tensor([ 6.7460e+01,  3.5870e+01, -9.0927e-01,  3.6520e-02,  5.6000e-01,\n","        -9.9919e-01, -6.0000e-03,  0.0000e+00,  4.2000e-02])\n","[train shard w09] shape=torch.Size([6381, 8, 9])  sample[6116][0]=tensor([ 9.5330e+01,  2.4400e+01, -6.6045e-01,  6.4047e-01,  1.5000e+00,\n","        -7.1788e-01, -8.4000e-02,  7.4000e-02,  7.2000e-01])\n","Saved 8 train shards for eval week 05 in /content/drive/MyDrive/bdb25-blitz/artifacts\n","\n","=== Eval week 06 ===\n","[val] shape=torch.Size([7201, 8, 9])  sample[2669][0]=tensor([ 5.4870e+01,  3.5610e+01,  0.0000e+00,  0.0000e+00,  9.1000e-01,\n","         9.5429e-01, -4.0000e-03,  4.0000e-03,  4.8000e-02])\n","[train shard w01] shape=torch.Size([8501, 8, 9])  sample[5723][0]=tensor([ 4.1440e+01,  1.7500e+01, -1.1231e+00,  1.2459e-01,  7.4000e-01,\n","        -9.9390e-01, -1.0000e-02,  2.5000e-03,  9.2500e-02])\n","[train shard w02] shape=torch.Size([7759, 8, 9])  sample[6036][0]=tensor([ 8.4190e+01,  2.5060e+01, -9.9684e-01,  1.6252e-01,  7.3000e-01,\n","        -9.8697e-01, -3.5000e-02,  2.0000e-02,  2.5250e-01])\n","[train shard w03] shape=torch.Size([8541, 8, 9])  sample[7471][0]=tensor([ 1.0504e+02,  2.9810e+01, -1.4884e+00, -6.9409e-02,  2.5000e-01,\n","        -9.9891e-01, -2.0000e-03,  2.0000e-03,  8.0000e-03])\n","[train shard w04] shape=torch.Size([7348, 8, 9])  sample[7023][0]=tensor([ 6.9360e+01,  2.9810e+01, -2.8283e-01, -1.8870e-01,  3.7000e-01,\n","        -8.3186e-01, -2.2500e-02, -1.0000e-02,  1.7750e-01])\n","[train shard w05] shape=torch.Size([7982, 8, 9])  sample[357][0]=tensor([ 7.1820e+01,  1.7760e+01, -2.3644e-01,  8.1227e-02,  7.1000e-01,\n","        -9.4575e-01, -2.8000e-02,  4.0000e-03,  1.6200e-01])\n","[train shard w07] shape=torch.Size([6915, 8, 9])  sample[6869][0]=tensor([ 7.7580e+01,  3.1820e+01, -3.9625e-03, -2.9737e-02,  2.5100e+00,\n","        -1.3208e-01, -2.0000e-03,  1.4000e-02,  7.2000e-02])\n","[train shard w08] shape=torch.Size([7319, 8, 9])  sample[6091][0]=tensor([ 4.7360e+01,  2.8820e+01, -3.6255e+00, -5.0115e-01, -3.5000e-01,\n","        -9.9058e-01, -2.2500e-02, -5.0000e-03,  1.6250e-01])\n","[train shard w09] shape=torch.Size([6381, 8, 9])  sample[1198][0]=tensor([ 3.6610e+01,  2.9720e+01, -3.1290e-01, -1.3301e-01,  6.1000e-01,\n","        -9.2030e-01, -3.2500e-02, -2.5000e-03,  1.0750e-01])\n","Saved 8 train shards for eval week 06 in /content/drive/MyDrive/bdb25-blitz/artifacts\n","\n","=== Eval week 07 ===\n","[val] shape=torch.Size([6915, 8, 9])  sample[1211][0]=tensor([ 4.5360e+01,  3.6310e+01, -8.1861e-02, -7.3476e-02,  7.0000e-01,\n","        -7.4419e-01, -1.2500e-02,  7.5000e-03,  1.6500e-01])\n","[train shard w01] shape=torch.Size([8501, 8, 9])  sample[1590][0]=tensor([ 5.5130e+01,  3.5100e+01, -2.2094e-02, -2.0295e-02,  3.9000e-01,\n","        -7.3645e-01,  2.5000e-03,  2.5000e-03,  3.5000e-02])\n","[train shard w02] shape=torch.Size([7759, 8, 9])  sample[5428][0]=tensor([ 5.6620e+01,  2.6960e+01, -3.3865e-01,  1.2212e-01,  5.0000e-01,\n","        -9.4070e-01, -4.2500e-02,  0.0000e+00,  3.3000e-01])\n","[train shard w03] shape=torch.Size([8541, 8, 9])  sample[6346][0]=tensor([ 8.9490e+01,  2.8640e+01, -8.0116e-01, -8.1101e-01,  6.1000e-01,\n","        -7.0277e-01, -5.0000e-03, -2.5000e-03,  7.5000e-03])\n","[train shard w04] shape=torch.Size([7348, 8, 9])  sample[4515][0]=tensor([ 5.2830e+01,  1.7840e+01, -2.2445e-01,  1.8364e-01,  1.0300e+00,\n","        -7.7395e-01, -1.5000e-02,  7.5000e-03,  1.6250e-01])\n","[train shard w05] shape=torch.Size([7982, 8, 9])  sample[6118][0]=tensor([1.1037e+02, 3.1940e+01, 1.1934e-01, 4.8485e+00, 2.5300e+00, 2.4607e-02,\n","        6.6000e-02, 7.1800e-01, 4.4500e+00])\n","[train shard w06] shape=torch.Size([7201, 8, 9])  sample[6693][0]=tensor([ 9.8370e+01,  2.1070e+01, -6.9453e-01,  7.1946e-01,  1.1400e+00,\n","        -6.9453e-01, -8.6000e-02,  6.8000e-02,  7.0000e-01])\n","[train shard w08] shape=torch.Size([7319, 8, 9])  sample[4322][0]=tensor([ 8.5610e+01,  2.2510e+01,  1.8000e-02, -9.8367e-02,  1.1400e+00,\n","         1.8000e-01, -2.2000e-02, -2.0000e-02,  1.5600e-01])\n","[train shard w09] shape=torch.Size([6381, 8, 9])  sample[3659][0]=tensor([ 3.5460e+01,  2.9510e+01, -3.6275e-03, -1.9668e-02,  8.0000e-01,\n","        -1.8138e-01, -5.0000e-03,  0.0000e+00,  2.0000e-02])\n","Saved 8 train shards for eval week 07 in /content/drive/MyDrive/bdb25-blitz/artifacts\n","\n","=== Eval week 08 ===\n","[val] shape=torch.Size([7319, 8, 9])  sample[2934][0]=tensor([ 3.3230e+01,  2.7800e+01,  8.3552e-03, -5.4946e-03,  7.7000e-01,\n","         8.3552e-01,  0.0000e+00, -4.0000e-03,  2.0000e-02])\n","[train shard w01] shape=torch.Size([8501, 8, 9])  sample[807][0]=tensor([ 9.7020e+01,  2.4720e+01,  3.0752e-03,  9.5154e-03,  9.5000e-01,\n","         3.0752e-01,  1.7500e-02, -5.0000e-03,  1.7500e-02])\n","[train shard w02] shape=torch.Size([7759, 8, 9])  sample[7567][0]=tensor([ 4.8400e+01,  3.2160e+01, -8.3225e-01,  1.1386e-01,  9.1000e-01,\n","        -9.9077e-01, -8.4000e-02,  8.0000e-03,  6.4200e-01])\n","[train shard w03] shape=torch.Size([8541, 8, 9])  sample[4297][0]=tensor([ 2.9490e+01,  1.7940e+01,  1.3869e-01, -1.9121e-02,  7.7000e-01,\n","         9.9063e-01,  1.0000e-02,  2.4000e-02,  1.3800e-01])\n","[train shard w04] shape=torch.Size([7348, 8, 9])  sample[3236][0]=tensor([ 4.0260e+01,  3.0410e+01,  0.0000e+00,  0.0000e+00,  6.3000e-01,\n","         5.2592e-01,  5.0000e-03, -2.5000e-03,  2.5000e-03])\n","[train shard w05] shape=torch.Size([7982, 8, 9])  sample[1772][0]=tensor([1.0807e+02, 2.2990e+01, 0.0000e+00, 0.0000e+00, 9.2000e-01, 1.8515e-01,\n","        0.0000e+00, 2.0000e-03, 0.0000e+00])\n","[train shard w06] shape=torch.Size([7201, 8, 9])  sample[4328][0]=tensor([ 2.9980e+01,  3.5960e+01, -2.2613e+00, -4.1993e-01,  1.4500e+00,\n","        -9.8319e-01, -8.0000e-03, -2.0000e-03,  3.0000e-02])\n","[train shard w07] shape=torch.Size([6915, 8, 9])  sample[3136][0]=tensor([ 5.2250e+01,  1.7920e+01, -1.9439e+00,  6.1887e-01, -3.6000e-01,\n","        -9.5287e-01,  2.0000e-02,  5.0000e-03,  2.9500e-01])\n","[train shard w09] shape=torch.Size([6381, 8, 9])  sample[2119][0]=tensor([ 4.7140e+01,  3.2280e+01, -6.9996e-01,  7.5562e-01,  3.2000e-01,\n","        -6.7957e-01, -1.2500e-02,  1.0000e-02,  8.7500e-02])\n","Saved 8 train shards for eval week 08 in /content/drive/MyDrive/bdb25-blitz/artifacts\n","\n","=== Eval week 09 ===\n","[val] shape=torch.Size([6381, 8, 9])  sample[2904][0]=tensor([ 3.6980e+01,  2.6660e+01, -2.2998e-01, -2.7296e-03,  2.2000e-01,\n","        -9.9993e-01, -2.8000e-02,  4.0000e-03,  2.9400e-01])\n","[train shard w01] shape=torch.Size([8501, 8, 9])  sample[79][0]=tensor([ 3.7510e+01,  2.5180e+01,  4.2375e-02, -4.2478e-02,  7.4000e-01,\n","         7.0624e-01,  5.0000e-03,  5.0000e-03,  5.5000e-02])\n","[train shard w02] shape=torch.Size([7759, 8, 9])  sample[4193][0]=tensor([3.5390e+01, 2.9720e+01, 8.9638e-02, 7.9781e-02, 9.7000e-01, 7.4699e-01,\n","        4.0000e-03, 3.0000e-02, 1.5000e-01])\n","[train shard w03] shape=torch.Size([8541, 8, 9])  sample[115][0]=tensor([ 3.0720e+01,  3.4580e+01,  3.0633e-02, -2.5722e-02,  7.7000e-01,\n","         7.6582e-01,  0.0000e+00, -1.0000e-02,  4.6000e-02])\n","[train shard w04] shape=torch.Size([7348, 8, 9])  sample[810][0]=tensor([ 9.7770e+01,  2.2570e+01, -8.2995e-01, -9.4158e-03,  9.4000e-01,\n","        -9.9994e-01, -2.5000e-03,  5.0000e-03,  2.0000e-02])\n","[train shard w05] shape=torch.Size([7982, 8, 9])  sample[442][0]=tensor([ 4.0350e+01,  3.3100e+01,  9.7645e-03,  2.1576e-03,  5.3000e-01,\n","         9.7645e-01, -5.0000e-03, -7.5000e-03,  7.5000e-03])\n","[train shard w06] shape=torch.Size([7201, 8, 9])  sample[6045][0]=tensor([9.5820e+01, 3.2260e+01, 0.0000e+00, 0.0000e+00, 9.0000e-01, 8.6698e-01,\n","        0.0000e+00, 5.0000e-03, 5.0000e-03])\n","[train shard w07] shape=torch.Size([6915, 8, 9])  sample[1164][0]=tensor([3.5860e+01, 4.3210e+01, 6.7865e-02, 9.8966e-02, 9.9000e-01, 5.6554e-01,\n","        6.0000e-03, 6.0000e-03, 8.8000e-02])\n","[train shard w08] shape=torch.Size([7319, 8, 9])  sample[752][0]=tensor([ 3.1040e+01,  2.9550e+01,  0.0000e+00, -0.0000e+00, -2.5000e-01,\n","         1.9560e-01, -5.0000e-03,  0.0000e+00,  2.5000e-03])\n","Saved 8 train shards for eval week 09 in /content/drive/MyDrive/bdb25-blitz/artifacts\n"]}],"id":"aSNQa4tT29tk"},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BlitzTransformer(nn.Module):\n","    \"\"\"\n","    Input:  x [B, K, F*]  (K defenders, F* can vary; we fix to feature_len internally)\n","    Output: logits [B]\n","    \"\"\"\n","    def __init__(self,\n","                 feature_len=9,\n","                 model_dim=128,\n","                 num_heads=4,\n","                 num_layers=2,\n","                 dim_feedforward=512,\n","                 dropout=0.1):\n","        super().__init__()\n","        self.feature_len = feature_len\n","\n","        self.bn = nn.BatchNorm1d(feature_len)\n","\n","        self.embed = nn.Sequential(\n","            nn.Linear(feature_len, model_dim),\n","            nn.ReLU(),\n","            nn.LayerNorm(model_dim),\n","            nn.Dropout(dropout),\n","        )\n","\n","        enc_layer = nn.TransformerEncoderLayer(\n","            d_model=model_dim,\n","            nhead=num_heads,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout,\n","            batch_first=True,\n","        )\n","        self.enc = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n","\n","        self.reduce = nn.Linear(model_dim * 2, model_dim)\n","        self.head = nn.Sequential(\n","            nn.Linear(model_dim, model_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(model_dim, model_dim // 4),\n","            nn.ReLU(),\n","            nn.LayerNorm(model_dim // 4),\n","            nn.Linear(model_dim // 4, 1),\n","        )\n","\n","    @staticmethod\n","    def _fixF(x: torch.Tensor, F_target: int) -> torch.Tensor:\n","        \"\"\"Pad with zeros or truncate to match F_target on the last dimension.\"\"\"\n","        F_cur = x.shape[-1]\n","        if F_cur == F_target:\n","            return x\n","        if F_cur < F_target:\n","            pad = x.new_zeros(*x.shape[:-1], F_target - F_cur)\n","            return torch.cat([x, pad], dim=-1)\n","        return x[..., :F_target]\n","\n","    def forward(self, x, mask=None):\n","        x = self._fixF(x, self.feature_len)               # [B,K,F*] → [B,K,F]\n","\n","        # ⬇️ correct permutation round-trip\n","        x = x.permute(0, 2, 1)                            # [B,F,K]\n","        x = self.bn(x)                                    # BN over feature dim (F)\n","        x = x.permute(0, 2, 1)                            # ✅ back to [B,K,F]\n","\n","        x = self.embed(x)                                 # [B,K,D]\n","        h = self.enc(x)                                   # [B,K,D]\n","\n","        if mask is None:\n","            mask = (x.abs().sum(dim=-1) > 0).float()      # [B,K]\n","        m = mask.unsqueeze(-1)                            # [B,K,1]\n","        safe = m.sum(dim=1).clamp_min(1e-6)\n","        mean = (h * m).sum(dim=1) / safe                  # [B,D]\n","        mx   = (h + (1.0 - m) * (-1e9)).amax(dim=1)       # [B,D]\n","        pooled = torch.cat([mean, mx], dim=-1)            # [B,2D]\n","        pooled = self.reduce(pooled)                      # [B,D]\n","        logit  = self.head(pooled).squeeze(-1)            # [B]\n","        return logit\n"],"metadata":{"id":"p0CEAwCpSYLB"},"execution_count":null,"outputs":[],"id":"p0CEAwCpSYLB"},{"cell_type":"code","source":["\n","from torch.utils.data import TensorDataset, DataLoader\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from torch.optim import AdamW\n","pd.options.mode.chained_assignment = None\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"9WXK0BekSY_Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757868671910,"user_tz":240,"elapsed":493,"user":{"displayName":"Aarush Ghosh","userId":"07665484170756829341"}},"outputId":"ab4330a5-a79f-4b4e-f081-125a172427a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"id":"9WXK0BekSY_Q"},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","def ensure_feature_dim(x, F_expected):\n","    \"\"\"Pad with zeros or truncate to match F_expected.\"\"\"\n","    F = x.shape[-1]\n","    if F == F_expected:\n","        return x\n","    if F < F_expected:\n","        pad = torch.zeros(*x.shape[:-1], F_expected - F, device=x.device, dtype=x.dtype)\n","        return torch.cat([x, pad], dim=-1)\n","    # F > F_expected: truncate (not ideal, better to regenerate consistently)\n","    return x[..., :F_expected]"],"metadata":{"id":"1UfKwe_GBRWh"},"execution_count":null,"outputs":[],"id":"1UfKwe_GBRWh"},{"cell_type":"code","source":["import os, glob, torch\n","import torch.nn as nn\n","from torch.utils.data import IterableDataset, DataLoader, TensorDataset\n","\n","# ---------- streaming dataset over shards ----------\n","class ShardStream(IterableDataset):\n","    \"\"\"Streams samples from shard files (one sample at a time).\"\"\"\n","    def __init__(self, feat_paths, tgt_paths, device=None):\n","        assert len(feat_paths) == len(tgt_paths), \"Mismatched shard counts\"\n","        self.feat_paths = feat_paths\n","        self.tgt_paths  = tgt_paths\n","        self.device     = device\n","    def __iter__(self):\n","        for fp, tp in zip(self.feat_paths, self.tgt_paths):\n","            X = torch.load(fp, map_location=\"cpu\").to(dtype=torch.float32)   # [N,K,F*]\n","            y = torch.load(tp, map_location=\"cpu\").to(dtype=torch.float32)   # [N]\n","            for i in range(X.shape[0]):\n","                xi, yi = X[i], y[i]\n","                if self.device:\n","                    xi = xi.to(self.device, non_blocking=True)\n","                    yi = yi.to(self.device, non_blocking=True)\n","                yield xi, yi\n","\n","# ------------ training loop ------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","batch_size = 64\n","learning_rate = 2e-4\n","num_epochs = 10\n","early_stopping_patience = 5\n","\n","ART = \"/content/drive/MyDrive/bdb25-blitz/artifacts\"\n","weeks_train = [1,2,3,4,5,6,7,8,9]\n","\n","for week_eval in weeks_train:\n","    print(f\"\\n######## WEEK {week_eval:02d} ########\")\n","\n","    # collect train shards\n","    feat_paths = sorted(glob.glob(os.path.join(ART, f\"features_train_week{week_eval:02d}_shard_w*.pt\")))\n","    tgt_paths  = sorted(glob.glob(os.path.join(ART, f\"targets_train_week{week_eval:02d}_shard_w*.pt\")))\n","    if not feat_paths:\n","        raise FileNotFoundError(f\"No train shards for eval week {week_eval:02d} in {ART}\")\n","\n","    # load val\n","    vaX = torch.load(os.path.join(ART, f\"features_val_week{week_eval:02d}.pt\"), map_location=\"cpu\").to(torch.float32)\n","    vaY = torch.load(os.path.join(ART, f\"targets_val_week{week_eval:02d}.pt\"),  map_location=\"cpu\").to(torch.float32)\n","\n","    # decide a single feature_len (BN & first linear need a fixed size).\n","    # pick the max feature width across val + all shards\n","    F_candidates = [vaX.shape[-1]]\n","    for fp in feat_paths:\n","        with torch.no_grad():\n","            F_candidates.append(torch.load(fp, map_location=\"cpu\").shape[-1])\n","    F_model = max(F_candidates)\n","    print(f\"[week {week_eval:02d}] inferred feature_len (F_model) = {F_model}\")\n","\n","    # class imbalance across all shards\n","    pos = neg = 0\n","    for tp in tgt_paths:\n","        y = torch.load(tp, map_location=\"cpu\").to(torch.float32)\n","        pos += int((y == 1).sum().item())\n","        neg += int((y == 0).sum().item())\n","    pos_weight = torch.tensor([max(1.0, neg / max(1, pos))], device=device)\n","    print(f\"[week {week_eval:02d}] pos={pos} neg={neg} pos_weight={pos_weight.item():.2f}\")\n","\n","    # model / opt / loss\n","    model = BlitzTransformer(\n","        feature_len=F_model,   # <-- key: BN & first Linear expect this width\n","        model_dim=128, num_heads=4, num_layers=2,\n","        dim_feedforward=512, dropout=0.1\n","    ).to(device)\n","    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-2)\n","\n","    # loaders\n","    train_stream = ShardStream(feat_paths, tgt_paths, device=device)\n","    train_loader = DataLoader(train_stream, batch_size=batch_size, shuffle=False, num_workers=0)\n","    val_loader   = DataLoader(TensorDataset(vaX.to(device), vaY.to(device)),\n","                              batch_size=batch_size, shuffle=False, num_workers=0)\n","\n","    # train/eval\n","    best_val, no_improve = float(\"inf\"), 0\n","    for epoch in range(num_epochs):\n","        # at top of the week loop\n","        ckpt_best = os.path.join(ART, f\"best_model_week{week_eval:02d}.pth\")\n","        ckpt_last = os.path.join(ART, f\"last_model_week{week_eval:02d}.pth\")\n","        best_val, no_improve = float(\"inf\"), 0\n","        saved_any = False\n","        # train\n","        model.train(); run = 0.0; n = 0\n","        first_batch_logged = False\n","        for xb, yb in train_loader:\n","            if not first_batch_logged:\n","                print(f\"[train] xb shape {tuple(xb.shape)}  (B,K,F*), model.feature_len={model.feature_len}\")\n","                first_batch_logged = True\n","            optimizer.zero_grad()\n","            logits = model(xb)                  # model pads/truncates internally to feature_len\n","            loss = criterion(logits, yb)\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            run += loss.item()*xb.size(0); n += xb.size(0)\n","        train_loss = run / max(1, n)\n","\n","        # val\n","        model.eval(); vrun = 0.0; vn = 0; correct = 0\n","        first_val_logged = False\n","        with torch.no_grad():\n","            for xb, yb in val_loader:\n","                if not first_val_logged:\n","                    print(f\"[val]   xb shape {tuple(xb.shape)}  (B,K,F*), model.feature_len={model.feature_len}\")\n","                    first_val_logged = True\n","                logits = model(xb)\n","                vloss = criterion(logits, yb)\n","                vrun += vloss.item()*xb.size(0); vn += xb.size(0)\n","                preds = (torch.sigmoid(logits) >= 0.5).long()\n","                correct += (preds == yb.long()).sum().item()\n","        val_loss = vrun / max(1, vn)\n","        val_acc  = correct / max(1, vn)\n","        print(f\"Epoch {epoch+1:02d}  train {train_loss:.4f}  val {val_loss:.4f}  acc {val_acc:.3f}\")\n","\n","        if val_loss < best_val:\n","          best_val, no_improve = val_loss, 0\n","          torch.save(model.state_dict(), ckpt_best)\n","          saved_any = True\n","        else:\n","            no_improve += 1\n","            if no_improve >= early_stopping_patience:\n","                print(\"Early stopping.\")\n","                break\n","\n","        # after the epoch loop finishes (always save a fallback)\n","        torch.save(model.state_dict(), ckpt_last)\n","        print(f\"Saved fallback checkpoint: {ckpt_last}\")\n","        if not saved_any:\n","            # also mirror as \"best\" to simplify downstream code\n","            torch.save(model.state_dict(), ckpt_best)\n","            print(f\"No improvement checkpoint found; mirrored last -> {ckpt_best}\")\n"],"metadata":{"id":"U4cGKGwVSdUb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757875042436,"user_tz":240,"elapsed":6367848,"user":{"displayName":"Aarush Ghosh","userId":"07665484170756829341"}},"outputId":"c7d8bb27-5d68-4e22-df0b-ec079e1078c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","######## WEEK 01 ########\n","[week 01] inferred feature_len (F_model) = 9\n","[week 01] pos=182 neg=59264 pos_weight=325.63\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 01  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week01.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week01.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 02  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week01.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week01.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 03  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week01.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week01.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 04  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week01.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week01.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 05  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week01.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week01.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 06  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week01.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week01.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 07  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week01.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week01.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 08  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week01.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week01.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 09  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week01.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week01.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 10  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week01.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week01.pth\n","\n","######## WEEK 02 ########\n","[week 02] inferred feature_len (F_model) = 9\n","[week 02] pos=182 neg=60006 pos_weight=329.70\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 01  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week02.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week02.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 02  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week02.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week02.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 03  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week02.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week02.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 04  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week02.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week02.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 05  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week02.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week02.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 06  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week02.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week02.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 07  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week02.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week02.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 08  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week02.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week02.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 09  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week02.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week02.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 10  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week02.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week02.pth\n","\n","######## WEEK 03 ########\n","[week 03] inferred feature_len (F_model) = 9\n","[week 03] pos=175 neg=59231 pos_weight=338.46\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 01  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week03.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week03.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 02  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week03.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week03.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 03  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week03.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week03.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 04  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week03.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week03.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 05  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week03.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week03.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 06  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week03.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week03.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 07  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week03.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week03.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 08  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week03.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week03.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 09  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week03.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week03.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 10  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week03.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week03.pth\n","\n","######## WEEK 04 ########\n","[week 04] inferred feature_len (F_model) = 9\n","[week 04] pos=210 neg=60389 pos_weight=287.57\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 01  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week04.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week04.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 02  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week04.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week04.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 03  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week04.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week04.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 04  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week04.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week04.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 05  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week04.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week04.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 06  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week04.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week04.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 07  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week04.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week04.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 08  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week04.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week04.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 09  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week04.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week04.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 10  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week04.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week04.pth\n","\n","######## WEEK 05 ########\n","[week 05] inferred feature_len (F_model) = 9\n","[week 05] pos=203 neg=59762 pos_weight=294.39\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 01  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week05.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week05.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 02  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week05.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week05.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 03  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week05.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week05.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 04  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week05.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week05.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 05  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week05.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week05.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 06  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week05.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week05.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 07  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week05.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week05.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 08  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week05.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week05.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 09  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week05.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week05.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 10  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week05.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week05.pth\n","\n","######## WEEK 06 ########\n","[week 06] inferred feature_len (F_model) = 9\n","[week 06] pos=182 neg=60564 pos_weight=332.77\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 01  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week06.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week06.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 02  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week06.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week06.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 03  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week06.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week06.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 04  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week06.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week06.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 05  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week06.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week06.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 06  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week06.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week06.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 07  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week06.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week06.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 08  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week06.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week06.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 09  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week06.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week06.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 10  train nan  val nan  acc 0.995\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week06.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week06.pth\n","\n","######## WEEK 07 ########\n","[week 07] inferred feature_len (F_model) = 9\n","[week 07] pos=203 neg=60829 pos_weight=299.65\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 01  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week07.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week07.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 02  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week07.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week07.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 03  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week07.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week07.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 04  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week07.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week07.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 05  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week07.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week07.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 06  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week07.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week07.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 07  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week07.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week07.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 08  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week07.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week07.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 09  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week07.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week07.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 10  train nan  val nan  acc 0.998\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week07.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week07.pth\n","\n","######## WEEK 08 ########\n","[week 08] inferred feature_len (F_model) = 9\n","[week 08] pos=189 neg=60439 pos_weight=319.78\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 01  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week08.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week08.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 02  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week08.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week08.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 03  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week08.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week08.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 04  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week08.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week08.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 05  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week08.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week08.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 06  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week08.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week08.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 07  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week08.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week08.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 08  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week08.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week08.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 09  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week08.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week08.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 10  train nan  val nan  acc 0.996\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week08.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week08.pth\n","\n","######## WEEK 09 ########\n","[week 09] inferred feature_len (F_model) = 9\n","[week 09] pos=210 neg=61356 pos_weight=292.17\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 01  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week09.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week09.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 02  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week09.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week09.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 03  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week09.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week09.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 04  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week09.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week09.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 05  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week09.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week09.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 06  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week09.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week09.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 07  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week09.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week09.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 08  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week09.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week09.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 09  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week09.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week09.pth\n","[train] xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","[val]   xb shape (64, 8, 9)  (B,K,F*), model.feature_len=9\n","Epoch 10  train nan  val nan  acc 0.999\n","Saved fallback checkpoint: /content/drive/MyDrive/bdb25-blitz/artifacts/last_model_week09.pth\n","No improvement checkpoint found; mirrored last -> /content/drive/MyDrive/bdb25-blitz/artifacts/best_model_week09.pth\n"]}],"id":"U4cGKGwVSdUb"}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}